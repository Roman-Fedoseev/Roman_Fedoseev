# Предсказание ценовых интервалов (p05–p95)  
## с оптимизацией метрики IoU (Intersection over Union)

---

## Постановка задачи

Необходимо предсказать **ценовой интервал** для товара — **5-й и 95-й квантили цены**, оптимизируя качество **не по MAE**, а **напрямую по метрике IoU** между истинным и предсказанным интервалами.

---

## Ключевая идея решения

Решение строится на трех фундаментальных принципах:

1. **Раздельное моделирование нижней и верхней границы**  
   - отдельная модель для `p05`
   - отдельная модель для `p95`

2. **Продвинутый feature engineering**, основанный **исключительно на train-данных**  
   (строгая защита от data leakage)

3. **Калибровка ширины интервала** на валидации  
   с прямой оптимизацией **IoU**, вдохновленная идеями *Conformal Prediction*

---

## Архитектура решения
Train \
├── Feature Engineering \
│ \
├── Model_low (p05) \
│ └── Optuna → best params \
│ \
├── Model_high (p95) \
│ └── Optuna → best params \
│ \
├── Calibration (validation) \
│ └── Grid search по (q_low, q_high) \
│ └── max IoU \
│ \
└── Retrain on full train \
└── Apply calibrated intervals to test

---

## Feature Engineering

Финальный набор признаков — результат **итеративного отбора**.  
Я тестировал разные поднаборы фичей, удалял слабые и шумные признаки,  
и в итоге получил устойчивый набор, максимизирующий IoU.

Признаки:
- погодные
- сезонные
- агрегаты по train
- категориальные признаки (для CatBoost)

---

## Две независимые модели
Почему так:
- квантили асимметричны
- нижняя и верхняя границы имеют разную динамику
- единая модель хуже контролирует ширину интервала

Для каждой модели отдельно запускался Optuna с подбором:

- depth
- learning_rate
- l2_leaf_reg
- random_strength
- bagging_temperature
- min_data_in_leaf

---

## Калибровка интервалов (ключевая часть)

После обучения моделей их предсказания не используются напрямую.
Применяется калибровка ширины интервала, вдохновленная идеями
Conformal Prediction.

На валидации считаются ошибки:

nonconf_low  = pred_p05 - true_p05
nonconf_high = true_p95 - pred_p95

Они отражают, насколько модель недооценивает соответствующие границы.

Двойной перебор квантилей

Перебираются пары (α_low, α_high):
alphas = np.linspace(0.1, 0.9, 81)

Для каждой пары вычисляется:
q_low  = quantile(nonconf_low,  1 - α_low  / 2)
q_high = quantile(nonconf_high, 1 - α_high / 2)


Формируются откалиброванные интервалы:
p05 = pred_p05 - q_low
p95 = pred_p95 + q_high

Для каждой пары считается:
IoU = |intersection(true_interval, predicted_interval)|
      / |union(true_interval, predicted_interval)|

Выбирается пара (q_low, q_high), максимизирующая IoU.

---

## Финальное обучение

После подбора калибровочных коэффициентов:
- число итераций берется из best_iteration
- модели переобучаются на всем train
- найденные q_low, q_high применяются к test

---
