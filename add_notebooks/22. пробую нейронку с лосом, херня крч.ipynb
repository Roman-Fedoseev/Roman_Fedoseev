{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d94ef7-6dc1-40f5-acf8-89ef26b08149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение NN моделей...\n",
      "Epoch 20 | Val Loss: 0.3087 | LR: 5.000000e-04\n",
      "Early stop at epoch 27\n",
      "Epoch 20 | Val Loss: 0.4980 | LR: 1.000000e-03\n",
      "Epoch 40 | Val Loss: 0.4945 | LR: 1.000000e-03\n",
      "Epoch 60 | Val Loss: 0.4887 | LR: 5.000000e-04\n",
      "Early stop at epoch 74\n",
      "Поиск оптимальных q...\n",
      "Best IoU: 0.2391 with q_low: -0.1171, q_high: -0.0627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import copy\n",
    "\n",
    "# Глобальная фиксация\n",
    "SEED = 322\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# 1. ЗАГРУЗКА И ПОДГОТОВКА\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = train[train['price_p05'] > 0]\n",
    "train['dt'] = pd.to_datetime(train['dt'])\n",
    "test['dt'] = pd.to_datetime(test['dt'])\n",
    "\n",
    "# 2. FEATURE ENGINEERING (из актуального CatBoost)\n",
    "def create_smart_features(df, train_ref=None):\n",
    "    if train_ref is not None:\n",
    "        prod_price_map = train_ref.groupby('product_id')['price_p05'].mean().to_dict()\n",
    "        df['global_prod_avg'] = df['product_id'].map(prod_price_map)\n",
    "        cat_price_map = train_ref.groupby('third_category_id')['price_p05'].mean().to_dict()\n",
    "        df['global_cat_avg'] = df['third_category_id'].map(cat_price_map)\n",
    "        for col in ['management_group_id', 'first_category_id', 'third_category_id']:\n",
    "            df[f'std_p05_{col}'] = df[col].map(train_ref.groupby(col)['price_p05'].std().to_dict())\n",
    "            df[f'std_p95_{col}'] = df[col].map(train_ref.groupby(col)['price_p95'].std().to_dict())\n",
    "    \n",
    "    cat_stores_map = df.groupby('third_category_id')['n_stores'].transform('mean')\n",
    "    df['store_density_ratio'] = df['n_stores'] / (cat_stores_map + 1e-6)\n",
    "    df['temp_hum_index'] = df['avg_temperature'] * (df['avg_humidity'] / 100)\n",
    "    df['category_breadth'] = df.groupby(['dt', 'third_category_id'])['product_id'].transform('nunique')\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['dt'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['dt'].dt.month / 12)\n",
    "    return df\n",
    "\n",
    "train = create_smart_features(train, train_ref=train)\n",
    "test = create_smart_features(test, train_ref=train)\n",
    "\n",
    "cat_features = ['management_group_id', 'first_category_id', 'activity_flag']\n",
    "num_features = [\n",
    "    'n_stores', 'precpt', 'avg_temperature', 'avg_humidity', 'avg_wind_level', \n",
    "    'week_of_year', 'month_sin', 'month_cos', 'global_prod_avg', 'global_cat_avg', \n",
    "    'store_density_ratio', 'temp_hum_index', 'category_breadth'\n",
    "]\n",
    "std_cols = [c for c in train.columns if 'std_p' in c and 'dow' not in c and 'second' not in c]\n",
    "num_features += std_cols\n",
    "\n",
    "# Заполнение пропусков и кодирование\n",
    "train[num_features] = train[num_features].fillna(train[num_features].mean())\n",
    "test[num_features] = test[num_features].fillna(train[num_features].mean())\n",
    "\n",
    "label_encoders = {}\n",
    "embedding_sizes = []\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    full_data = pd.concat([train[col], test[col]]).astype(str)\n",
    "    le.fit(full_data)\n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    embedding_sizes.append((len(le.classes_), min(50, (len(le.classes_) + 1) // 2)))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train[num_features] = scaler.fit_transform(train[num_features])\n",
    "test[num_features] = scaler.transform(test[num_features])\n",
    "\n",
    "# 3. КВАНТИЛЬНЫЙ ЛОСС (PINBALL LOSS)\n",
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, quantile=0.5):\n",
    "        super().__init__()\n",
    "        self.quantile = quantile\n",
    "    def forward(self, preds, target):\n",
    "        errors = target - preds\n",
    "        loss = torch.max((self.quantile - 1) * errors, self.quantile * errors)\n",
    "        return loss.mean()\n",
    "\n",
    "# 4. МОДЕЛЬ И ДАТАСЕТ\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df, cats, nums, target_name=None):\n",
    "        self.cats = torch.LongTensor(df[cats].values)\n",
    "        self.nums = torch.FloatTensor(df[nums].values)\n",
    "        self.targets = torch.FloatTensor(df[target_name].values) if target_name else None\n",
    "    def __len__(self): return len(self.cats)\n",
    "    def __getitem__(self, i):\n",
    "        if self.targets is not None: return self.cats[i], self.nums[i], self.targets[i]\n",
    "        return self.cats[i], self.nums[i]\n",
    "\n",
    "class TabularNN(nn.Module):\n",
    "    def __init__(self, emb_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_emb + n_cont, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x_cat, x_num):\n",
    "        x = torch.cat([e(x_cat[:, i]) for i, e in enumerate(self.embs)], 1)\n",
    "        return self.net(torch.cat([x, x_num], 1)).squeeze()\n",
    "\n",
    "# 5. ОБУЧЕНИЕ\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CoverageMAE(nn.Module):\n",
    "    def __init__(self, quantile, penalty_weight=10.0):\n",
    "        super().__init__()\n",
    "        self.quantile = quantile\n",
    "        self.penalty_weight = penalty_weight\n",
    "\n",
    "    def forward(self, preds, target):\n",
    "        # 1. Базовый MAE (минимизируем отклонение)\n",
    "        mae_loss = F.l1_loss(preds, target)\n",
    "        \n",
    "        # 2. Штраф за покрытие (Hinge-style)\n",
    "        errors = target - preds\n",
    "        \n",
    "        if self.quantile < 0.5:\n",
    "            # Для p05: штрафуем, если предсказание ВЫШЕ таргета (target < preds)\n",
    "            # Мы хотим, чтобы только 5% данных были ниже границы\n",
    "            violation = F.relu(-errors) \n",
    "        else:\n",
    "            # Для p95: штрафуем, если предсказание НИЖЕ таргета (target > preds)\n",
    "            # Мы хотим, чтобы только 5% данных были выше границы\n",
    "            violation = F.relu(errors)\n",
    "            \n",
    "        coverage_penalty = violation.mean()\n",
    "        \n",
    "        # Итоговый лосс: баланс между точностью и соблюдением границы\n",
    "        return mae_loss + self.penalty_weight * coverage_penalty\n",
    "\n",
    "# Обновляем функцию обучения, чтобы она использовала новый лосс\n",
    "def train_nn(train_loader, val_loader, q, epochs=150, patience=10):\n",
    "    model = TabularNN(embedding_sizes, len(num_features)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    \n",
    "    # penalty_weight можно подбирать: \n",
    "    # если интервалы слишком узкие — увеличиваем, если слишком широкие — уменьшаем.\n",
    "    criterion = CoverageMAE(quantile=q, penalty_weight=15.0) \n",
    "    \n",
    "    # Добавим планировщик скорости обучения для лучшей сходимости\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_state = None\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for c, n, t in train_loader:\n",
    "            c, n, t = c.to(device), n.to(device), t.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(c, n), t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for c, n, t in val_loader:\n",
    "                c, n, t = c.to(device), n.to(device), t.to(device)\n",
    "                val_loss += criterion(model(c, n), t).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss) # Снижаем LR, если лосс застрял\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss, best_state, counter = val_loss, copy.deepcopy(model.state_dict()), 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1} | Val Loss: {val_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6e}\")\n",
    "            \n",
    "        if counter >= patience:\n",
    "            print(f\"Early stop at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# Сплит по времени (как в CatBoost)\n",
    "train_parts, val_parts = [], []\n",
    "for _, group in train.groupby('dt'):\n",
    "    group = group.sample(frac=1, random_state=SEED)\n",
    "    idx = int(len(group) * 0.8)\n",
    "    train_parts.append(group.iloc[:idx]); val_parts.append(group.iloc[idx:])\n",
    "\n",
    "tr_df, val_df = pd.concat(train_parts), pd.concat(val_parts)\n",
    "\n",
    "# Модели\n",
    "loaders = {\n",
    "    'tr_low': DataLoader(TabularDataset(tr_df, cat_features, num_features, 'price_p05'), batch_size=4096, shuffle=True),\n",
    "    'val_low': DataLoader(TabularDataset(val_df, cat_features, num_features, 'price_p05'), batch_size=4096),\n",
    "    'tr_high': DataLoader(TabularDataset(tr_df, cat_features, num_features, 'price_p95'), batch_size=4096, shuffle=True),\n",
    "    'val_high': DataLoader(TabularDataset(val_df, cat_features, num_features, 'price_p95'), batch_size=4096)\n",
    "}\n",
    "\n",
    "print(\"Обучение NN моделей...\")\n",
    "nn_low = train_nn(loaders['tr_low'], loaders['val_low'], 0.05)\n",
    "nn_high = train_nn(loaders['tr_high'], loaders['val_high'], 0.95)\n",
    "\n",
    "# 6. CONFORMAL CALIBRATION (РАЗДЕЛЬНЫЕ АЛЬФЫ)\n",
    "def get_preds(model, loader):\n",
    "    model.eval()\n",
    "    all_p = []\n",
    "    with torch.no_grad():\n",
    "        for c, n, _ in loader:\n",
    "            all_p.append(model(c.to(device), n.to(device)).cpu().numpy())\n",
    "    return np.concatenate(all_p)\n",
    "\n",
    "calib_low = get_preds(nn_low, loaders['val_low'])\n",
    "calib_high = get_preds(nn_high, loaders['val_high'])\n",
    "\n",
    "nonconf_low = calib_low - val_df['price_p05'].values\n",
    "nonconf_high = val_df['price_p95'].values - calib_high\n",
    "\n",
    "def calculate_iou(l_t, u_t, l_p, u_p):\n",
    "    inter = np.maximum(0, np.minimum(u_t, u_p) - np.maximum(l_t, l_p))\n",
    "    union = (u_t - l_t) + (u_p - l_p) - inter\n",
    "    return np.mean(inter / (union + 1e-6))\n",
    "\n",
    "print(\"Поиск оптимальных q...\")\n",
    "best_iou, best_qs = -1, (0, 0)\n",
    "for al in np.linspace(0.1, 0.9, 41):\n",
    "    ql = np.quantile(nonconf_low, 1 - al/2)\n",
    "    for ah in np.linspace(0.1, 0.9, 41):\n",
    "        qh = np.quantile(nonconf_high, 1 - ah/2)\n",
    "        score = calculate_iou(val_df['price_p05'].values, val_df['price_p95'].values, calib_low - ql, np.maximum(calib_high + qh, calib_low - ql + 0.001))\n",
    "        if score > best_iou:\n",
    "            best_iou, best_qs = score, (ql, qh)\n",
    "\n",
    "q_low, q_high = best_qs\n",
    "print(f\"Best IoU: {best_iou:.4f} with q_low: {q_low:.4f}, q_high: {q_high:.4f}\")\n",
    "\n",
    "# 7. SUBMISSION\n",
    "test_loader = DataLoader(TabularDataset(test, cat_features, num_features), batch_size=4096, shuffle=False)\n",
    "def predict_test(model, loader):\n",
    "    model.eval()\n",
    "    all_p = []\n",
    "    with torch.no_grad():\n",
    "        for c, n in loader: all_p.append(model(c.to(device), n.to(device)).cpu().numpy())\n",
    "    return np.concatenate(all_p)\n",
    "\n",
    "test['price_p05'] = predict_test(nn_low, test_loader) - q_low\n",
    "test['price_p95'] = predict_test(nn_high, test_loader) + q_high\n",
    "test['price_p95'] = np.maximum(test['price_p95'], test['price_p05'] + 0.001)\n",
    "\n",
    "test[['row_id', 'price_p05', 'price_p95']].to_csv('submission_nn_conformal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a46dd-a025-4790-bea4-e02c2d0d306c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
